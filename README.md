# ğŸ¤ Advanced Voice-to-Voice AI Assistant

A cutting-edge, real-time voice assistant with advanced features like intelligent interrupts, conversation memory, and seamless AI integration. Built for natural, fluid conversations with state-of-the-art AI models.

## âœ¨ Key Features

### ğŸ§  **Intelligent AI Integration**
- **Google Gemini 2.0 Flash**: Latest AI with 2M token context window
- **LM Studio Support**: Any OpenAI-compatible local models  
- **Smart Context Management**: Hierarchical memory with STMs, LTMs, and conversation summaries
- **Creative Responses**: Configurable temperature for personality control

### ğŸ¯ **Advanced Voice Processing**
- **Real-time Interrupts**: Intelligent speech detection with accurate conversation logging
- **Voice Activity Detection**: Hands-free operation with configurable sensitivity
- **Voice Cloning**: High-quality synthesis with any reference voice using Chatterbox TTS
- **Emotion Control**: Fine-tune expressiveness and speaking style

### âš¡ **Performance Optimized**
- **Streaming Synthesis**: Low-latency progressive audio generation
- **GPU Acceleration**: CUDA-optimized for real-time performance
- **Smart Caching**: Conversation memory with 60s update intervals
- **Adaptive Processing**: Scales from CPU-only to high-end GPU setups

### ğŸ’¬ **Conversation Intelligence**
- **Interrupt Tracking**: Knows exactly what was heard vs intended
- **Memory Hierarchy**: Long-term and short-term memory with automatic summarization
- **Context Preservation**: Maintains conversation continuity across sessions
- **Accurate Logging**: Reflects true back-and-forth dialog including interruptions

## ğŸ—ï¸ Advanced Architecture

```
[Microphone] â†’ [VAD] â†’ [Whisper STT] â†’ [Memory Hierarchy] â†’ [Gemini 2.0/LLM] â†’ [Streaming TTS] â†’ [Speakers]
     â†‘                     â†“                     â†“                                       â†“               â†“
[Interrupt Detection] â†’ [Context Manager] â†’ [Conversation Logger] â†’ [Progressive Synthesis] â†’ [Audio Pipeline]
     â†‘                                                                                                     â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Real-time Intelligent Voice Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components
- **Interrupt Engine**: Millisecond-accurate speech detection with context preservation
- **Memory Manager**: Hierarchical conversation storage (STMs â†’ LTMs â†’ Summaries)
- **Streaming Synthesizer**: Progressive TTS with sentence-level timing tracking
- **Context Orchestrator**: Manages 2M+ token context windows intelligently

## ğŸ“‹ Prerequisites

### 1. AI Model Setup

**Option A: Google Gemini (Recommended)**
- Get API key from [Google AI Studio](https://makersuite.google.com/)
- Supports 2M token context, grounding, and latest features

**Option B: Local LLM via LM Studio**
1. Download [LM Studio](https://lmstudio.ai/)
2. Load a model (Llama 3.2, Phi-3, Mistral)
3. Start server on `http://localhost:1234`

### 2. System Requirements

- **Python**: 3.9+ (3.11+ recommended)
- **GPU**: CUDA-compatible GPU recommended (RTX 3060+ ideal)
- **Memory**: 12GB+ RAM for optimal performance
- **Storage**: 10GB+ for models and voice caches
- **Audio**: Quality microphone and speakers/headphones

## ğŸš€ Quick Installation

### Windows (PowerShell)
```powershell
git clone <this-repo>
cd voice-chatbot
.\install.ps1  # Automated installation script
```

### Linux/macOS
```bash
git clone <this-repo>
cd voice-chatbot
chmod +x install.sh
./install.sh  # Automated installation script
```

### Manual Installation

1. **Clone and Setup**:
   ```bash
   git clone <this-repo>
   cd voice-chatbot
   ```

2. **Install Chatterbox TTS**:
   ```bash
   git clone https://github.com/resemble-ai/chatterbox.git
   cd chatterbox && pip install -e . && cd ..
   ```

3. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Platform-specific Audio**:
   
   **Windows**: `pip install pipwin && pipwin install pyaudio`
   
   **macOS**: `brew install portaudio && pip install pyaudio`
   
   **Linux**: `sudo apt install portaudio19-dev && pip install pyaudio`

## âš™ï¸ Configuration

All settings are in `configs/config.py` for easy customization:

```python
# AI Model Configuration
GEMINI_API_KEY = "your-api-key-here"
GEMINI_MODEL = "gemini-2.0-flash-exp"
LLM_TEMPERATURE = 1.0  # Creative responses

# Performance Settings
ENABLE_HIGH_PERFORMANCE = True
ENABLE_FAST_TTS = True
MAX_HISTORY_MESSAGES = 2000  # Full context utilization

# Voice Configuration  
VOICE_REFERENCE_PATH = VOICES_DIR / "your_voice.wav"
VOICE_TEMPERATURE = 0.5  # TTS creativity
VOICE_EXAGGERATION = 0.7  # Emotion intensity

# Audio Optimization
CHUNK_SIZE = 480  # VAD-optimized
VAD_AGGRESSIVENESS = 2  # Interrupt sensitivity
SAMPLE_RATE = 16000
```

## ğŸ¯ Usage Examples

### Basic Usage
```bash
# With Gemini (recommended)
python main.py --use-gemini

# With local LLM
python main.py

# High-performance mode
python main.py --use-gemini --high-performance --fast-tts
```

### Advanced Options
```bash
# Maximum performance
python main.py --use-gemini --streaming --high-performance --fast-tts --no-grace-period

# Custom voice and settings
python main.py --use-gemini --voice voices/my_voice.wav --vad-aggressiveness 3

# Development/testing
python main.py --text-mode  # Text-only for debugging
```

### Available Modes

| Flag | Description |
|------|-------------|
| `--use-gemini` | Use Google Gemini 2.0 Flash with grounding |
| `--streaming` | Enable progressive TTS synthesis |
| `--high-performance` | Aggressive optimizations |
| `--fast-tts` | Ultra-fast voice synthesis |
| `--no-grace-period` | Immediate interrupt response |
| `--text-mode` | Text-only testing mode |

## ğŸ­ Advanced Voice Features

### Voice Cloning Setup
1. **Record Reference Audio**:
   - 10-30 seconds of clear speech
   - Multiple sentences preferred
   - WAV format, 16kHz+ sample rate

2. **Voice Quality Tips**:
   - Record in quiet environment
   - Speak naturally and clearly
   - Avoid filler words (um, uh)
   - Include variety in tone

3. **Parameter Tuning**:
   ```python
   VOICE_TEMPERATURE = 0.5    # Lower = more consistent
   VOICE_CFG_WEIGHT = 0.5     # Lower = faster synthesis  
   VOICE_EXAGGERATION = 0.7   # Higher = more emotional
   ```

### Voice Validation
The system automatically validates voice files:
- âœ… Duration analysis (optimal: 9-30 seconds)
- âœ… Sample rate check (16kHz minimum)
- âœ… Audio quality metrics
- âœ… Format compatibility

## ğŸ”§ Advanced Features

### Interrupt Intelligence
- **Millisecond Accuracy**: Detects speech start within 30ms
- **Context Preservation**: Tracks exactly what was heard vs intended
- **Smart Logging**: Conversation logs reflect true dialog flow
- **Resumption Context**: AI knows what was interrupted

### Memory Hierarchy
```
Conversations â†’ Individual Summaries â†’ STMs (5 summaries) â†’ LTMs (5 STMs) â†’ Long-term Context
     â†“                    â†“                â†“                    â†“                    â†“
   Real-time        Key Points      Thematic Groups     Major Patterns      Persistent Memory
```

### Performance Monitoring
- **Real-time Metrics**: LLM, TTS, and memory timing
- **Session Summaries**: Performance reports on exit
- **Bottleneck Detection**: Identifies slow operations
- **Resource Usage**: GPU, memory, and processing stats

## ğŸ“Š Performance Benchmarks

### Typical Response Times (RTX 4070)
- **Speech Recognition**: 500-800ms
- **Gemini 2.0 Response**: 300-600ms  
- **TTS Synthesis**: 2-4s (streaming starts immediately)
- **Total Latency**: 1-2s to first audio

### Optimization Results
- **Memory Processing**: 98% reduction (4ms every 60s vs every request)
- **TTS Speed**: 40% faster with optimized settings
- **Context Loading**: 95% faster with intelligent caching
- **Interrupt Response**: <50ms audio stopping

## ğŸ§ª Advanced Usage

### Testing & Debugging
```bash
# Performance benchmarking
python test_optimizations.py

# Voice quality testing  
python convert_jr_voice.py  # Voice conversion utilities

# Memory system testing
python examples/simple_test.py

# Audio pipeline testing
python trim_voice_sample.py  # Voice sample processing
```

### Memory Management
```bash
# View conversation logs
ls conversation_logs/

# Check summaries
ls conversation_logs/summaries/

# Monitor STM/LTM hierarchy
ls conversation_logs/stm_summaries/
ls conversation_logs/ltm_summaries/
```

## ğŸ” Troubleshooting

### Performance Issues

**1. Slow Response Times**
```bash
# Use high-performance mode
python main.py --use-gemini --high-performance --fast-tts

# Check GPU utilization
nvidia-smi

# Monitor performance
python analyze_performance.py
```

**2. Memory Usage**
- Reduce `MAX_HISTORY_MESSAGES` for lower memory
- Disable `AUTO_SUMMARIZE_CONVERSATIONS` temporarily
- Use smaller Whisper model (`tiny` or `base`)

**3. Audio Issues**
```bash
# Test audio devices
python -c "import pyaudio; print([pyaudio.PyAudio().get_device_info_by_index(i)['name'] for i in range(pyaudio.PyAudio().get_device_count())])"

# Check VAD settings
python main.py --vad-aggressiveness 1  # Lower sensitivity
```

### Common Error Fixes

| Error | Solution |
|-------|----------|
| `CUDA out of memory` | Use `--device cpu` or smaller models |
| `VAD processing error: Frame size must be 480` | Already fixed in latest version |
| `Grounding API error` | Grounding auto-disabled, system continues normally |
| `Summary generation hanging` | Uses stable Gemini 1.5 Flash for summarization |
| `Import errors` | Run `pip install -r requirements.txt` |

## ğŸ“ Project Architecture

```
voice-assistant/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.py              # Centralized configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio/                 # Audio processing pipeline
â”‚   â”‚   â”œâ”€â”€ input_manager.py   # VAD and interrupt detection
â”‚   â”‚   â”œâ”€â”€ stream_manager.py  # Audio I/O management
â”‚   â”‚   â”œâ”€â”€ sound_effects.py   # UI audio feedback
â”‚   â”‚   â””â”€â”€ vad.py            # Voice activity detection
â”‚   â”œâ”€â”€ llm/                   # Language model integrations
â”‚   â”‚   â”œâ”€â”€ gemini_llm.py     # Google Gemini 2.0 wrapper
â”‚   â”‚   â””â”€â”€ openai_compatible.py # LM Studio compatibility
â”‚   â”œâ”€â”€ pipeline/              # Core orchestration
â”‚   â”‚   â”œâ”€â”€ voice_assistant.py # Main coordinator with interrupts
â”‚   â”‚   â”œâ”€â”€ conversation_logger.py # Dialog tracking
â”‚   â”‚   â”œâ”€â”€ conversation_summarizer.py # Memory processing
â”‚   â”‚   â”œâ”€â”€ hierarchical_memory_manager.py # STM/LTM system
â”‚   â”‚   â””â”€â”€ streaming_tts.py   # Progressive synthesis
â”‚   â”œâ”€â”€ stt/                   # Speech recognition
â”‚   â”‚   â””â”€â”€ whisper_stt.py     # OpenAI Whisper integration
â”‚   â”œâ”€â”€ tts/                   # Text-to-speech
â”‚   â”‚   â””â”€â”€ chatterbox_wrapper.py # Chatterbox TTS wrapper
â”‚   â””â”€â”€ utils/                 # Utilities and optimizations
â”‚       â”œâ”€â”€ logger.py          # Timestamped logging system
â”‚       â”œâ”€â”€ performance_monitor.py # Metrics tracking
â”‚       â”œâ”€â”€ performance_optimizer.py # Speed optimizations
â”‚       â””â”€â”€ tts_optimizer.py   # Voice synthesis tuning
â”œâ”€â”€ conversation_logs/         # Persistent conversation storage
â”œâ”€â”€ voices/                    # Voice reference files
â”œâ”€â”€ models/                    # Cached AI models
â”œâ”€â”€ main.py                   # Application entry point
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                # This comprehensive guide
```

## ğŸ”¬ Development

### Contributing Guidelines
1. **Fork** the repository
2. **Create** feature branch: `git checkout -b feature/amazing-feature`
3. **Follow** existing code patterns and add tests
4. **Update** documentation as needed
5. **Submit** PR with detailed description

### Development Setup
```bash
# Development installation
git clone --recursive <repo-url>
cd voice-assistant
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt -e .

# Run tests
pytest tests/ --cov=src

# Code quality
black src/ tests/
flake8 src/ tests/
```

### Architecture Principles
- **Modular Design**: Each component is independently testable
- **Error Resilience**: Graceful degradation when features fail
- **Performance First**: Real-time constraints drive design decisions
- **User Experience**: Natural conversation flow prioritized

## ğŸ“ˆ Roadmap

### Current Version (v2.0)
- âœ… Intelligent interrupt tracking
- âœ… Gemini 2.0 Flash integration
- âœ… Hierarchical memory system  
- âœ… Performance optimizations
- âœ… Streaming TTS synthesis

### Upcoming Features (v2.1)
- ğŸ”„ Web interface for remote access
- ğŸ”„ Multi-language support
- ğŸ”„ Custom wake word detection
- ğŸ”„ Voice emotion recognition
- ğŸ”„ Real-time voice style transfer

### Future Vision (v3.0)
- ğŸš€ Multi-modal input (vision + voice)
- ğŸš€ Distributed processing
- ğŸš€ Plugin architecture
- ğŸš€ Advanced personality modeling

## ğŸ¤ Community

### Support Channels
- **Issues**: [GitHub Issues](https://github.com/yourusername/repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/repo/discussions)
- **Discord**: [Community Server](https://discord.gg/yourinvite)

### Recognition
Special thanks to:
- **Resemble AI** - Chatterbox TTS system
- **Google** - Gemini AI models  
- **OpenAI** - Whisper speech recognition
- **LM Studio** - Local LLM server
- **Contributors** - Community improvements

## ğŸ“œ License & Legal

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) for details.

### Third-party Licenses
- Chatterbox TTS: Apache 2.0
- Whisper: MIT License
- Dependencies: Various open-source licenses

### Usage Rights
- âœ… Commercial use permitted
- âœ… Modification and distribution allowed
- âœ… Private use encouraged
- â— Attribution required

## ğŸ‰ Getting Started

Ready to experience the future of voice AI? 

1. **Quick Start**: `python main.py --use-gemini`
2. **Join Community**: [Discord Server](https://discord.gg/yourinvite)
3. **Read Docs**: Browse this README thoroughly
4. **Contribute**: Help improve the project

---

**ğŸ¤ Start talking to the future today! ğŸ¤–**

Built with â¤ï¸ by the open-source AI community.

---

### Appendix: Quick Reference

#### Essential Commands
```bash
# Basic usage
python main.py --use-gemini

# Performance mode  
python main.py --use-gemini --high-performance --fast-tts

# Development
python main.py --text-mode

# Custom voice
python main.py --use-gemini --voice voices/my_voice.wav
```

#### Key Configuration
```python
# In configs/config.py
GEMINI_API_KEY = "your-key"           # Required for Gemini
VOICE_REFERENCE_PATH = "voice.wav"    # Your voice sample
MAX_RESPONSE_TOKENS = 150             # Response length
LLM_TEMPERATURE = 1.0                 # Creativity level
```

#### Performance Tips
- Use `--high-performance` for speed
- Enable `--fast-tts` for quick synthesis  
- Set `VAD_AGGRESSIVENESS = 2` for responsive interrupts
- Use RTX 3060+ GPU for optimal performance

**Happy building! ğŸš€**